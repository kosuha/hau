<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>오디오 스트리밍 테스트 (PCM)</title>
    <style>
        body { font-family: sans-serif; padding: 20px; }
        #status { margin-bottom: 10px; font-weight: bold; }
        #response { margin-top: 15px; border: 1px solid #ccc; padding: 10px; min-height: 100px; background-color: #f9f9f9; white-space: pre-wrap; }
        button { padding: 10px 15px; margin-right: 10px; cursor: pointer; }
        button:disabled { cursor: not-allowed; opacity: 0.6; }
    </style>
</head>
<body>
    <h1>오디오 스트리밍 테스트 (PCM)</h1>

    <div id="status">연결 대기 중...</div>

    <button id="startButton">녹음 시작</button>
    <button id="stopButton" disabled>녹음 중지</button>

    <h2>서버 응답:</h2>
    <div id="response"></div>

    <script>
        const statusDiv = document.getElementById('status');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const responseDiv = document.getElementById('response');

        let socket;
        const SERVER_URL = 'ws://localhost:3000/ws'; // 실제 서버 주소로 변경하세요

        // --- Web Audio API 관련 변수 ---
        let audioContext; // 입력 및 출력에 사용될 AudioContext
        let inputStream; // 마이크 입력 스트림
        let inputNode; // 마이크 스트림 소스 노드
        let scriptProcessorNode; // 오디오 처리 노드 (PCM 변환 및 전송)
        let targetSampleRate = 16000; // API 요구 입력 샘플링 레이트
        let outputSampleRate = 24000; // API 제공 출력 샘플링 레이트
        const BUFFER_SIZE = 4096; // 처리할 오디오 버퍼 크기 (조절 가능)
        // ---------------------------------

        function connectWebSocket() {
            socket = new WebSocket(SERVER_URL);
            socket.binaryType = 'arraybuffer'; // 서버와 PCM 데이터(ArrayBuffer)를 주고받기 위해 설정

            socket.onopen = () => {
                statusDiv.textContent = '서버에 연결되었습니다.';
                console.log('WebSocket connected');
                startButton.disabled = false;
            };

            socket.onmessage = (event) => {
                if (event.data instanceof ArrayBuffer) {
                    // 서버로부터 원시 PCM 오디오 데이터(ArrayBuffer) 수신
                    const pcmData = event.data;
                    console.log(`Received raw PCM audio: ${pcmData.byteLength} bytes`);
                    responseDiv.textContent += `[오디오 데이터 ${pcmData.byteLength} bytes 수신]\n`;
                    responseDiv.scrollTop = responseDiv.scrollHeight;

                    playRawPCM(pcmData);

                } else {
                    // 텍스트 메시지 처리 (기존과 동일)
                    console.log('Message from server:', event.data);
                    responseDiv.textContent += event.data + '\n';
                    responseDiv.scrollTop = responseDiv.scrollHeight;
                }
            };

            socket.onerror = (error) => {
                statusDiv.textContent = 'WebSocket 오류 발생. 콘솔을 확인하세요.';
                console.error('WebSocket Error:', error);
                startButton.disabled = true;
                stopButton.disabled = true;
                cleanupAudioResources(); // 오류 시 오디오 리소스 정리
            };

            socket.onclose = (event) => {
                statusDiv.textContent = `연결 종료됨 (코드: ${event.code})`;
                console.log('WebSocket disconnected:', event.reason);
                startButton.disabled = true;
                stopButton.disabled = true;
                cleanupAudioResources(); // 연결 종료 시 오디오 리소스 정리
            };
        }

        // Web Audio API 초기화 (필요 시)
        function initializeAudioContext() {
            if (!audioContext || audioContext.state === 'closed') {
                // AudioContext 생성 (브라우저 호환성 고려)
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                if (!window.AudioContext) {
                    alert('Web Audio API가 지원되지 않는 브라우저입니다.');
                    return null;
                }
                try {
                    audioContext = new AudioContext({ sampleRate: outputSampleRate }); // 출력 샘플링 레이트에 맞춰 생성 시도
                    console.log(`AudioContext created. Sample rate: ${audioContext.sampleRate}`);
                    // 출력 샘플링 레이트와 다를 경우 재생 시 리샘플링됨
                } catch (e) {
                    console.warn(`Could not create AudioContext with desired sample rate ${outputSampleRate}, using default.`, e);
                    audioContext = new AudioContext(); // 기본값으로 생성
                }
            }
             // 사용자가 상호작용하기 전에 AudioContext가 시작되도록 함 (브라우저 정책)
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }
            return audioContext;
        }

        // 원시 PCM 데이터(ArrayBuffer)를 Web Audio API로 재생하는 함수
        function playRawPCM(pcmData) {
            const currentAudioContext = initializeAudioContext();
            if (!currentAudioContext) return;

            // 16비트 PCM 데이터를 Float32 (-1.0 ~ 1.0) 데이터로 변환
            const pcmInt16 = new Int16Array(pcmData);
            const numSamples = pcmInt16.length;
            const audioBuffer = currentAudioContext.createBuffer(1, numSamples, outputSampleRate); // 모노, 샘플 수, 목표 샘플링 레이트
            const channelData = audioBuffer.getChannelData(0);

            for (let i = 0; i < numSamples; i++) {
                channelData[i] = pcmInt16[i] / 32768.0; // 16비트 정수를 float로 변환
            }

            // 오디오 버퍼 소스 노드 생성 및 재생
            const sourceNode = currentAudioContext.createBufferSource();
            sourceNode.buffer = audioBuffer;
            sourceNode.connect(currentAudioContext.destination);
            sourceNode.onended = () => {
                console.log("Playback finished for this chunk.");
                responseDiv.textContent += `[오디오 재생 완료]\n`;
                responseDiv.scrollTop = responseDiv.scrollHeight;
            };
            sourceNode.start(); // 즉시 재생
            console.log("Starting playback of received PCM data.");
        }


        async function startRecording() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('브라우저가 오디오 입력을 지원하지 않습니다.');
                return;
            }

            const currentAudioContext = initializeAudioContext();
            if (!currentAudioContext) return;

            try {
                inputStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusDiv.textContent = '마이크 접근 성공. 녹음 준비 중...';

                inputNode = currentAudioContext.createMediaStreamSource(inputStream);
                const inputSampleRate = currentAudioContext.sampleRate; // 브라우저의 실제 입력 샘플링 레이트
                console.log(`Input sample rate: ${inputSampleRate} Hz`);

                // ScriptProcessorNode 생성 (버퍼 크기, 입력 채널 수, 출력 채널 수)
                // 주의: ScriptProcessorNode는 deprecated 상태이며, AudioWorklet 사용이 권장됨
                scriptProcessorNode = currentAudioContext.createScriptProcessor(BUFFER_SIZE, 1, 1);

                scriptProcessorNode.onaudioprocess = (event) => {
                    if (!socket || socket.readyState !== WebSocket.OPEN) {
                        console.warn("WebSocket not open, skipping audio processing.");
                        return;
                    }

                    const inputData = event.inputBuffer.getChannelData(0); // Float32Array 데이터
                    const outputData = downsampleBuffer(inputData, inputSampleRate, targetSampleRate); // 16kHz로 다운샘플링
                    const pcmData = convertFloat32ToInt16(outputData); // 16비트 PCM으로 변환 (ArrayBuffer)

                    // WebSocket으로 전송
                    socket.send(pcmData);
                    // console.log(`Sent ${pcmData.byteLength} bytes of PCM data`);
                };

                // 노드 연결: 마이크 입력 -> ScriptProcessor -> (여기서는 목적지 연결 안 함, 데이터만 추출)
                inputNode.connect(scriptProcessorNode);
                scriptProcessorNode.connect(currentAudioContext.destination); // 중요: 연결해야 onaudioprocess가 호출됨 (소리는 나지 않게 할 수 있음)
                // scriptProcessorNode.disconnect(currentAudioContext.destination); // 소리 출력을 원치 않으면 연결 후 바로 해제 가능 (브라우저마다 동작 다를 수 있음)

                statusDiv.textContent = '녹음 중... (16kHz PCM)';
                startButton.disabled = true;
                stopButton.disabled = false;
                console.log('Recording started (Raw PCM)');

            } catch (err) {
                console.error('마이크 접근 또는 오디오 처리 오류:', err);
                statusDiv.textContent = '마이크/오디오 오류. 권한 또는 설정을 확인하세요.';
                startButton.disabled = false;
                stopButton.disabled = true;
                cleanupAudioResources(); // 오류 시 정리
            }
        }

        // 간단한 다운샘플링 함수 (품질 저하 가능성 있음)
        function downsampleBuffer(buffer, inputRate, outputRate) {
            if (inputRate === outputRate) {
                return buffer;
            }
            const sampleRateRatio = inputRate / outputRate;
            const newLength = Math.round(buffer.length / sampleRateRatio);
            const result = new Float32Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            while (offsetResult < result.length) {
                const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                let accum = 0, count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }
                result[offsetResult] = accum / count; // 간단한 평균값 사용 (더 나은 필터링 필요)
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result;
        }

        // Float32Array를 Int16 ArrayBuffer (Little Endian)로 변환
        function convertFloat32ToInt16(buffer) {
            const l = buffer.length;
            const buf = new Int16Array(l);
            for (let i = 0; i < l; i++) {
                buf[i] = Math.min(1, Math.max(-1, buffer[i])) * 0x7FFF; // 클리핑 및 스케일링
            }
            return buf.buffer; // ArrayBuffer 반환
        }


        function stopRecording() {
            statusDiv.textContent = '녹음 중지 중...';
            console.log('Stopping recording...');

            if (inputStream) {
                inputStream.getTracks().forEach(track => track.stop()); // 마이크 스트림 중지
                inputStream = null;
            }

            if (scriptProcessorNode) {
                scriptProcessorNode.disconnect(); // 모든 연결 해제
                scriptProcessorNode.onaudioprocess = null; // 이벤트 핸들러 제거
                scriptProcessorNode = null;
            }

            if (inputNode) {
                inputNode.disconnect(); // 연결 해제
                inputNode = null;
            }

            // AudioContext는 재사용 가능하므로 닫지 않을 수 있음
            // if (audioContext && audioContext.state !== 'closed') {
            //     audioContext.close().then(() => console.log('AudioContext closed.'));
            // }

            startButton.disabled = false;
            stopButton.disabled = true;
            statusDiv.textContent = '녹음 중지됨.';
            console.log('Recording stopped.');
        }

        // 오디오 관련 리소스 정리 함수
        function cleanupAudioResources() {
            stopRecording(); // 녹음 중지 로직 재사용
            // 필요하다면 AudioContext 닫기 등 추가 정리
            console.log("Cleaned up audio resources.");
        }

        startButton.onclick = startRecording;
        stopButton.onclick = stopRecording;

        // 페이지 로드 시 웹소켓 연결 시작
        connectWebSocket();

    </script>
</body>
</html>